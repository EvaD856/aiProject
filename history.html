	<!doctype html>
<html>
<head>
<meta charset="UTF-8">
<title>AI Project</title>
<link rel="stylesheet" href="styles.css">
</head>

<body>
	<header>
		<img src="images/brain.png" alt="Rainbow cyber brain logo company">
		<blockquote>Modern AI Technology</blockquote>
		<br>
		<nav>
			<ul>
				<li><a href="index.html">Home</a></li>
				
				<li><a href="history.html">History</a></li>
				
				<li><a href="current.html">Current Technology</a></li>
				
				<li><a href="future.html">Future</a></li>
				
				<li><a href="contact.html">Contact Us</a></li>
				
			</ul>
		</nav>
	</header>
	
	<main>
		<h1>History</h1>
		<p>"In the first half of the 20th century, science fiction familiarized the world with the concept of artificially intelligent robots. It began with the “heartless” Tin man from the Wizard of Oz and continued with the humanoid robot that impersonated Maria in Metropolis.</p> <br>
		
		<p>Turing suggested that humans use available information as well as reason in order to solve problems and make decisions, so why can’t machines do the same thing? This was the logical framework of his 1950 paper, Computing Machinery and Intelligence in which he discussed how to build intelligent machines and how to test their intelligence.</p> <br>
		
		<p>First, computers needed to fundamentally change. Before 1949 computers lacked a key prerequisite for intelligence: they couldn’t store commands, only execute them. In other words, computers could be told what to do but couldn’t remember what they did. Second, computing was extremely expensive. In the early 1950s, the cost of leasing a computer ran up to $200,000 a month. Only prestigious universities and big technology companies could afford to dillydally in these uncharted waters. A proof of concept as well as advocacy from high profile people were needed to persuade funding sources that machine intelligence was worth pursuing.</p><br>
		
		<p>Five years later, the proof of concept was initialized through Allen Newell, Cliff Shaw, and Herbert Simon’s, Logic Theorist. The Logic Theorist was a program designed to mimic the problem solving skills of a human and was funded by Research and Development (RAND) Corporation. It’s considered by many to be the first artificial intelligence program and was presented at the Dartmouth Summer Research Project on Artificial Intelligence (DSRPAI) hosted by John McCarthy and Marvin Minsky in 1956.</p> <br>
		
		<p>From 1957 to 1974, AI flourished. Computers could store more information and became faster, cheaper, and more accessible. Machine learning algorithms also improved and people got better at knowing which algorithm to apply to their problem. Early demonstrations such as Newell and Simon’s General Problem Solver and Joseph Weizenbaum’s ELIZA showed promise toward the goals of problem solving and the interpretation of spoken language respectively.</p> <br>
		
		<p>In the 1980’s, AI was reignited by two sources: an expansion of the algorithmic toolkit, and a boost of funds. John Hopfield and David Rumelhart popularized “deep learning” techniques which allowed computers to learn using experience. On the other hand Edward Feigenbaum introduced expert systems which mimicked the decision making process of a human expert. </p><br>
		
		<p> During the 1990s and 2000s, many of the landmark goals of artificial intelligence had been achieved. In 1997, reigning world chess champion and grand master Gary Kasparov was defeated by IBM’s Deep Blue, a chess playing computer program. This highly publicized match was the first time a reigning world chess champion loss to a computer and served as a huge step towards an artificially intelligent decision making program. In the same year, speech recognition software, developed by Dragon Systems, was implemented on Windows. This was another great step forward but in the direction of the spoken language interpretation endeavor.</p><br>
		
		<p>We now live in the age of “big data,” an age in which we have the capacity to collect huge sums of information too cumbersome for a person to process. The application of artificial intelligence in this regard has already been quite fruitful in several industries such as technology, banking, marketing, and entertainment. We’ve seen that even if algorithms don’t improve much, big data and massive computing simply allow artificial intelligence to learn through brute force. There may be evidence that Moore’s law is slowing down a tad, but the increase in data certainly hasn’t lost any momentum. Breakthroughs in computer science, mathematics, or neuroscience all serve as potential outs through the ceiling of Moore’s Law".</p><br><br><br><br><br>
	</main>
	
	<img src="images/history.jpg" alt="old-styled computer">
	
	<footer>
		<h7>Source: https://sitn.hms.harvard.edu/flash/2017/history-artificial-intelligence/</h7><br>
		<h7>Images from pixabay.com</h7><br>
		<p>Copyright Section &copy;</p>
		<nav>
			<ul>
				
				<li><a href="index.html">Home</a></li>
				
				<li><a href="history.html">History</a></li>
				
				<li><a href="current.html">Current Technology</a></li>
				
				<li><a href="future.html">Future</a></li>
				
				<li><a href="contact.html">Contact Us</a></li>
				
			</ul>
		</nav>
	</footer>
	
</body>

</html>
